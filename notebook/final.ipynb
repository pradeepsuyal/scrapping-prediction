{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2329cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import urllib\n",
    "import string\n",
    "\n",
    "df = pd.read_excel(\"Input.xlsx\")\n",
    "max_row, max_col = df.shape\n",
    "print(max_row)\n",
    "\n",
    "df = df[['URL_ID','URL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed29385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"\n",
    "}\n",
    "\n",
    "for i in range(max_row):\n",
    "    url = df.iloc[i,1]\n",
    "    url_id = df.iloc[i,0]\n",
    "    print(url)\n",
    "    html = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(html.content,'lxml')\n",
    "    text = soup.find_all('p')\n",
    "    text = [t.text for t in text]\n",
    "    text = ' '.join(text)\n",
    "    remove = string.punctuation\n",
    "    remove = re.sub(r\"[.:-]+\", \"\", remove)\n",
    "    pattern = r\"[{}]\".format(remove + '-') \n",
    "    text = re.sub(pattern, \"\", text) \n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    #text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    #text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [x for x in text if len(x)>1]\n",
    "    text = ' '.join(text)\n",
    "    print(text)\n",
    "    df.iat[i,1] = text\n",
    "    df.iat[i,0] = url_id\n",
    "df.to_excel('Output_with_text.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aef65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for extracting_heading\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"\n",
    "}\n",
    "\n",
    "for i in range(max_row):\n",
    "    url = df.iloc[i,1]\n",
    "    url_id = df.iloc[i,0]\n",
    "    print(url)\n",
    "    html = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(html.content,'lxml')\n",
    "    text = soup.find_all('h1')\n",
    "    text = [t.text for t in text]\n",
    "    text = ' '.join(text)\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [x for x in text if len(x)>1]\n",
    "    text = ' '.join(text)\n",
    "    print(text)\n",
    "    df.iat[i,1] = text\n",
    "    df.iat[i,0] = url_id\n",
    "df.to_excel('Output_with_heading.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4669cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for extracting subheading\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"\n",
    "}\n",
    "\n",
    "for i in range(max_row):\n",
    "    url = df.iloc[i,1]\n",
    "    url_id = df.iloc[i,0]\n",
    "    print(url)\n",
    "    html = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(html.content,'lxml')\n",
    "    text = soup.find_all('h2')\n",
    "    text = [t.text for t in text]\n",
    "    text = ' '.join(text)\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [x for x in text if len(x)>1]\n",
    "    text = ' '.join(text)\n",
    "    print(text)\n",
    "    df.iat[i,1] = text\n",
    "    df.iat[i,0] = url_id\n",
    "\n",
    "df.to_excel('Output_with_h2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "972549be",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_heading = pd.read_excel('Output_with_heading.xlsx')\n",
    "article_heading['article_heading'] = article_heading['URL']\n",
    "article_heading = article_heading.drop('URL',axis = 1)\n",
    "\n",
    "article_text = pd.read_excel('Output_with_text.xlsx')\n",
    "\n",
    "article_text = article_text[['URL_ID','URL']]\n",
    "article_text['text'] = article_text['URL']\n",
    "article_text = article_text.drop('URL',axis=1)\n",
    "\n",
    "article_subheading = pd.read_excel('Output_with_h2.xlsx')\n",
    "article_subheading = article_subheading.fillna(\"is\")\n",
    "article_subheading['article_subheading'] = article_subheading['URL']\n",
    "article_subheading = article_subheading.drop('URL',axis=1)\n",
    "\n",
    "# create a new dataframe and add the article_text,article_heading,article_subheading\n",
    "article_df = pd.merge(article_text,article_heading,on='URL_ID')\n",
    "article_content = pd.merge(article_df,article_subheading,on='URL_ID')\n",
    "\n",
    "# join heading ,text and subheading in a single column name 'content' separated by ','\n",
    "article_content['content'] = article_df['article_heading'] + ',' + article_df['text'] + ',' + article_content['article_subheading']\n",
    "\n",
    "# drop the columns 'article_heading' and 'text' and 'article_subheading'\n",
    "article_content = article_content.drop(['article_heading','text','article_subheading'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9bd05e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>how is login logout time tracking for employee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>how does ai help to monitor retail shelf watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ai and its impact on the fashion industry ai i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>how do deep learning models predict old and ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>how artificial intelligence can boost your pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>167</td>\n",
       "      <td>role of big data in academia,can academia rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>168</td>\n",
       "      <td>statistical methods for sales forecasting in r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>169</td>\n",
       "      <td>behavior based chi square model to detect data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>170</td>\n",
       "      <td>what is data exfiltration,if we talk in terms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>171</td>\n",
       "      <td>impacts of covid 19 on food products,some vend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                            content\n",
       "0         1  how is login logout time tracking for employee...\n",
       "1         2  how does ai help to monitor retail shelf watch...\n",
       "2         3  ai and its impact on the fashion industry ai i...\n",
       "3         4  how do deep learning models predict old and ne...\n",
       "4         5  how artificial intelligence can boost your pro...\n",
       "..      ...                                                ...\n",
       "165     167  role of big data in academia,can academia rese...\n",
       "166     168  statistical methods for sales forecasting in r...\n",
       "167     169  behavior based chi square model to detect data...\n",
       "168     170  what is data exfiltration,if we talk in terms ...\n",
       "169     171  impacts of covid 19 on food products,some vend...\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10751e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_content.to_excel('article_content.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd52b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sudee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d9c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positve words in dictionary are 354\n",
      "Total negative words in dictionary are 2355\n"
     ]
    }
   ],
   "source": [
    "master_dict = pd.read_csv('./LoughranMcDonald_MasterDictionary_2020.csv')\n",
    "\n",
    "positive_dictionary = [x for x in master_dict[master_dict['Positive'] != 0]['Word']]\n",
    "negative_dictionary = [x for x in master_dict[master_dict['Negative'] != 0]['Word']]\n",
    "\n",
    "print(f\"Total positve words in dictionary are {len(positive_dictionary)}\")\n",
    "print(f\"Total negative words in dictionary are {len(negative_dictionary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b47ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the stopword set from basic english and the given list of stopwords\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "# upper case the stopwords\n",
    "#stop_words = {word.upper() for word in stop_words}\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(r'[^A-Za-z]',' ',text.upper())\n",
    "    tokenized_words = word_tokenize(text)\n",
    "    return tokenized_words\n",
    "\n",
    "def remove_stopwords(content):\n",
    "    content = content.upper()\n",
    "    content = content.split()\n",
    "    content = [word for word in content if word not in stop_words]\n",
    "    content = \" \".join(content)\n",
    "    return content\n",
    "\n",
    "def countfunc(store, words):\n",
    "    score = 0\n",
    "    for x in words:\n",
    "        if(x in store):\n",
    "            score = score+1\n",
    "    return score\n",
    "\n",
    "def polarity(positive_score, negative_score):\n",
    "    return (positive_score - negative_score)/((positive_score + negative_score)+ 0.000001)\n",
    "     \n",
    "\n",
    "def subjectivity(positive_score, negative_score, num_words):\n",
    "    return (positive_score+negative_score)/(num_words+ 0.000001)\n",
    "\n",
    "def syllable_morethan2(word):\n",
    "    if(len(word) > 2 and (word[-2:] == 'es' or word[-2:] == 'ed')):\n",
    "        return False\n",
    "    \n",
    "    count =0\n",
    "    vowels = ['a','e','i','o','u']\n",
    "    for i in word:\n",
    "        if(i.lower() in vowels):\n",
    "            count = count +1\n",
    "        \n",
    "    if(count > 2):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def fog_index_cal(average_sentence_length, percentage_complexwords):\n",
    "    return 0.4*(average_sentence_length + percentage_complexwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6c68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(w.upper() for w in stopwords.words('english'))\n",
    "# tokenize article content\n",
    "article_content['tokenized_content'] = article_content['content'].apply(tokenize)\n",
    "# remove stopwords\n",
    "article_content['tokenized_content'] = article_content['tokenized_content'].apply(lambda x: [w for w in x if not w in stopset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b9164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of positive words in the article\n",
    "article_content['POSITIVE SCORE'] = article_content['tokenized_content'].apply(lambda x: countfunc(positive_dictionary, x))\n",
    "\n",
    "#count the number of negative words in the article\n",
    "article_content['NEGATIVE SCORE'] = article_content['tokenized_content'].apply(lambda x: countfunc(negative_dictionary, x))\n",
    "\n",
    "#calculate the polarity score\n",
    "article_content['POLARITY SCORE'] = article_content.apply(lambda x: polarity(x['POSITIVE SCORE'], x['NEGATIVE SCORE']), axis=1)\n",
    "\n",
    "#calculate number of words after cleaning\n",
    "article_content['num_words'] = article_content['tokenized_content'].apply(lambda x: len(x))\n",
    "\n",
    "#calculate the subjectivity score\n",
    "article_content['SUBJECTIVITY SCORE'] = article_content.apply(lambda x: subjectivity(x['POSITIVE SCORE'], x['NEGATIVE SCORE'], x['num_words']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe33aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average sentence length\n",
    "#Average Sentence Length = the number of words / the number of sentences\n",
    "#first find the number of sentences\n",
    "article_content['num_sentences'] = article_content['content'].apply(lambda x: len(sent_tokenize(x)))\n",
    "article_content['AVG SENTENCE LENGTH'] = article_content['num_words']/article_content['num_sentences']\n",
    "#fog index\n",
    "#article_content['FOG INDEX'] = article_content.apply(lambda x: fog_index_cal(x['AVG SENTENCE LENGTH'], x['percentage_complexwords']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4432475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of complex of word\n",
    "article_content['num_complex_words'] = article_content['tokenized_content'].apply(lambda x: len([w for w in x if syllable_morethan2(w)]))\n",
    "article_content['PERCENTAGE OF COMPLEX WORDS'] = article_content['num_complex_words']/article_content['num_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed47b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fog index\n",
    "article_content['FOG INDEX'] = article_content.apply(lambda x: fog_index_cal(x['AVG SENTENCE LENGTH'], x['PERCENTAGE OF COMPLEX WORDS']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52da9d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Number of Words Per Sentence = the total number of words / the total number of sentences\n",
    "#first find total number of words \n",
    "article_content['total_num_words'] = article_content['tokenized_content'].apply(lambda x: sum([len(sent) for sent in x]))\n",
    "#find total number of sentences\n",
    "#article_content['total_num_sentences'] = article_content['num_sentences'].sum()\n",
    "#calculate average number of words per sentence\n",
    "article_content['AVG NUMBER OF WORDS PER SENTENCE'] = article_content['total_num_words']/article_content['num_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "883ddcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate complex words count\n",
    "article_content['COMPLEX WORD COUNT'] = article_content['tokenized_content'].apply(lambda x: len([w for w in x if syllable_morethan2(w)]))\n",
    "\n",
    "# calculate WORD COUNT\n",
    "article_content['WORD COUNT'] = article_content['tokenized_content'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2676ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_content['SYLLABLE PER WORD'] = article_content['tokenized_content'].apply(lambda x: sum([len(w) for w in x if syllable_morethan2(w)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ebc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "article_content['PERSONAL PRONOUN'] = article_content['content'].apply(lambda x: len(re.findall(r'\\b(i|we|my|ours|us)\\b', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73dec17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f69ae09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE AVERAGE WORD LENGTH\n",
    "article_content['num_char'] = article_content['content'].apply(lambda x: sum([len(w) for w in x]))\n",
    "\n",
    "article_content['AVG WORD LENGTH'] = article_content['num_char']/article_content['total_num_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a869aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>num_words</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>num_complex_words</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>total_num_words</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUN</th>\n",
       "      <th>num_char</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>how is login logout time tracking for employee...</td>\n",
       "      <td>[LOGIN, LOGOUT, TIME, TRACKING, EMPLOYEES, OFF...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>412</td>\n",
       "      <td>0.021845</td>\n",
       "      <td>24</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>175</td>\n",
       "      <td>0.424757</td>\n",
       "      <td>7.036570</td>\n",
       "      <td>2693</td>\n",
       "      <td>112.208333</td>\n",
       "      <td>175</td>\n",
       "      <td>412</td>\n",
       "      <td>1498</td>\n",
       "      <td>4</td>\n",
       "      <td>4305</td>\n",
       "      <td>1.598589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>how does ai help to monitor retail shelf watch...</td>\n",
       "      <td>[AI, HELP, MONITOR, RETAIL, SHELF, WATCHES, IN...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>377</td>\n",
       "      <td>0.039788</td>\n",
       "      <td>27</td>\n",
       "      <td>13.962963</td>\n",
       "      <td>177</td>\n",
       "      <td>0.469496</td>\n",
       "      <td>5.772984</td>\n",
       "      <td>2597</td>\n",
       "      <td>96.185185</td>\n",
       "      <td>177</td>\n",
       "      <td>377</td>\n",
       "      <td>1539</td>\n",
       "      <td>2</td>\n",
       "      <td>3978</td>\n",
       "      <td>1.531767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ai and its impact on the fashion industry ai i...</td>\n",
       "      <td>[AI, IMPACT, FASHION, INDUSTRY, AI, FAST, FASH...</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1060</td>\n",
       "      <td>0.050943</td>\n",
       "      <td>75</td>\n",
       "      <td>14.133333</td>\n",
       "      <td>558</td>\n",
       "      <td>0.526415</td>\n",
       "      <td>5.863899</td>\n",
       "      <td>7462</td>\n",
       "      <td>99.493333</td>\n",
       "      <td>558</td>\n",
       "      <td>1060</td>\n",
       "      <td>4869</td>\n",
       "      <td>13</td>\n",
       "      <td>11368</td>\n",
       "      <td>1.523452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>how do deep learning models predict old and ne...</td>\n",
       "      <td>[DEEP, LEARNING, MODELS, PREDICT, OLD, NEW, DR...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>255</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>14</td>\n",
       "      <td>18.214286</td>\n",
       "      <td>134</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>7.495910</td>\n",
       "      <td>1791</td>\n",
       "      <td>127.928571</td>\n",
       "      <td>134</td>\n",
       "      <td>255</td>\n",
       "      <td>1183</td>\n",
       "      <td>1</td>\n",
       "      <td>2765</td>\n",
       "      <td>1.543830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>how artificial intelligence can boost your pro...</td>\n",
       "      <td>[ARTIFICIAL, INTELLIGENCE, BOOST, PRODUCTIVITY...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>399</td>\n",
       "      <td>0.067669</td>\n",
       "      <td>32</td>\n",
       "      <td>12.468750</td>\n",
       "      <td>193</td>\n",
       "      <td>0.483709</td>\n",
       "      <td>5.180984</td>\n",
       "      <td>2698</td>\n",
       "      <td>84.312500</td>\n",
       "      <td>193</td>\n",
       "      <td>399</td>\n",
       "      <td>1717</td>\n",
       "      <td>20</td>\n",
       "      <td>4285</td>\n",
       "      <td>1.588213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                            content  \\\n",
       "0       1  how is login logout time tracking for employee...   \n",
       "1       2  how does ai help to monitor retail shelf watch...   \n",
       "2       3  ai and its impact on the fashion industry ai i...   \n",
       "3       4  how do deep learning models predict old and ne...   \n",
       "4       5  how artificial intelligence can boost your pro...   \n",
       "\n",
       "                                   tokenized_content  POSITIVE SCORE  \\\n",
       "0  [LOGIN, LOGOUT, TIME, TRACKING, EMPLOYEES, OFF...               4   \n",
       "1  [AI, HELP, MONITOR, RETAIL, SHELF, WATCHES, IN...               9   \n",
       "2  [AI, IMPACT, FASHION, INDUSTRY, AI, FAST, FASH...              31   \n",
       "3  [DEEP, LEARNING, MODELS, PREDICT, OLD, NEW, DR...               6   \n",
       "4  [ARTIFICIAL, INTELLIGENCE, BOOST, PRODUCTIVITY...              14   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  num_words  SUBJECTIVITY SCORE  \\\n",
       "0               5       -0.111111        412            0.021845   \n",
       "1               6        0.200000        377            0.039788   \n",
       "2              23        0.148148       1060            0.050943   \n",
       "3               1        0.714286        255            0.027451   \n",
       "4              13        0.037037        399            0.067669   \n",
       "\n",
       "   num_sentences  AVG SENTENCE LENGTH  num_complex_words  \\\n",
       "0             24            17.166667                175   \n",
       "1             27            13.962963                177   \n",
       "2             75            14.133333                558   \n",
       "3             14            18.214286                134   \n",
       "4             32            12.468750                193   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  total_num_words  \\\n",
       "0                     0.424757   7.036570             2693   \n",
       "1                     0.469496   5.772984             2597   \n",
       "2                     0.526415   5.863899             7462   \n",
       "3                     0.525490   7.495910             1791   \n",
       "4                     0.483709   5.180984             2698   \n",
       "\n",
       "   AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                        112.208333                 175         412   \n",
       "1                         96.185185                 177         377   \n",
       "2                         99.493333                 558        1060   \n",
       "3                        127.928571                 134         255   \n",
       "4                         84.312500                 193         399   \n",
       "\n",
       "   SYLLABLE PER WORD  PERSONAL PRONOUN  num_char  AVG WORD LENGTH  \n",
       "0               1498                 4      4305         1.598589  \n",
       "1               1539                 2      3978         1.531767  \n",
       "2               4869                13     11368         1.523452  \n",
       "3               1183                 1      2765         1.543830  \n",
       "4               1717                20      4285         1.588213  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "362a96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_content.to_excel('added_variables.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f424915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>num_words</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>num_complex_words</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>total_num_words</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUN</th>\n",
       "      <th>num_char</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>how is login logout time tracking for employee...</td>\n",
       "      <td>[LOGIN, LOGOUT, TIME, TRACKING, EMPLOYEES, OFF...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>412</td>\n",
       "      <td>0.021845</td>\n",
       "      <td>24</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>175</td>\n",
       "      <td>0.424757</td>\n",
       "      <td>7.036570</td>\n",
       "      <td>2693</td>\n",
       "      <td>112.208333</td>\n",
       "      <td>175</td>\n",
       "      <td>412</td>\n",
       "      <td>1498</td>\n",
       "      <td>4</td>\n",
       "      <td>4305</td>\n",
       "      <td>1.598589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>how does ai help to monitor retail shelf watch...</td>\n",
       "      <td>[AI, HELP, MONITOR, RETAIL, SHELF, WATCHES, IN...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>377</td>\n",
       "      <td>0.039788</td>\n",
       "      <td>27</td>\n",
       "      <td>13.962963</td>\n",
       "      <td>177</td>\n",
       "      <td>0.469496</td>\n",
       "      <td>5.772984</td>\n",
       "      <td>2597</td>\n",
       "      <td>96.185185</td>\n",
       "      <td>177</td>\n",
       "      <td>377</td>\n",
       "      <td>1539</td>\n",
       "      <td>2</td>\n",
       "      <td>3978</td>\n",
       "      <td>1.531767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                            content  \\\n",
       "0       1  how is login logout time tracking for employee...   \n",
       "1       2  how does ai help to monitor retail shelf watch...   \n",
       "\n",
       "                                   tokenized_content  POSITIVE SCORE  \\\n",
       "0  [LOGIN, LOGOUT, TIME, TRACKING, EMPLOYEES, OFF...               4   \n",
       "1  [AI, HELP, MONITOR, RETAIL, SHELF, WATCHES, IN...               9   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  num_words  SUBJECTIVITY SCORE  \\\n",
       "0               5       -0.111111        412            0.021845   \n",
       "1               6        0.200000        377            0.039788   \n",
       "\n",
       "   num_sentences  AVG SENTENCE LENGTH  num_complex_words  \\\n",
       "0             24            17.166667                175   \n",
       "1             27            13.962963                177   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  total_num_words  \\\n",
       "0                     0.424757   7.036570             2693   \n",
       "1                     0.469496   5.772984             2597   \n",
       "\n",
       "   AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                        112.208333                 175         412   \n",
       "1                         96.185185                 177         377   \n",
       "\n",
       "   SYLLABLE PER WORD  PERSONAL PRONOUN  num_char  AVG WORD LENGTH  \n",
       "0               1498                 4      4305         1.598589  \n",
       "1               1539                 2      3978         1.531767  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_content.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef5c0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_computing = article_content.drop(['content','tokenized_content','num_words','num_sentences','num_complex_words','total_num_words','num_char'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b865226f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUN</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.021845</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>0.424757</td>\n",
       "      <td>7.036570</td>\n",
       "      <td>112.208333</td>\n",
       "      <td>175</td>\n",
       "      <td>412</td>\n",
       "      <td>1498</td>\n",
       "      <td>4</td>\n",
       "      <td>1.598589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.039788</td>\n",
       "      <td>13.962963</td>\n",
       "      <td>0.469496</td>\n",
       "      <td>5.772984</td>\n",
       "      <td>96.185185</td>\n",
       "      <td>177</td>\n",
       "      <td>377</td>\n",
       "      <td>1539</td>\n",
       "      <td>2</td>\n",
       "      <td>1.531767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.050943</td>\n",
       "      <td>14.133333</td>\n",
       "      <td>0.526415</td>\n",
       "      <td>5.863899</td>\n",
       "      <td>99.493333</td>\n",
       "      <td>558</td>\n",
       "      <td>1060</td>\n",
       "      <td>4869</td>\n",
       "      <td>13</td>\n",
       "      <td>1.523452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID  POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0       1               4               5       -0.111111            0.021845   \n",
       "1       2               9               6        0.200000            0.039788   \n",
       "2       3              31              23        0.148148            0.050943   \n",
       "\n",
       "   AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            17.166667                     0.424757   7.036570   \n",
       "1            13.962963                     0.469496   5.772984   \n",
       "2            14.133333                     0.526415   5.863899   \n",
       "\n",
       "   AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                        112.208333                 175         412   \n",
       "1                         96.185185                 177         377   \n",
       "2                         99.493333                 558        1060   \n",
       "\n",
       "   SYLLABLE PER WORD  PERSONAL PRONOUN  AVG WORD LENGTH  \n",
       "0               1498                 4         1.598589  \n",
       "1               1539                 2         1.531767  \n",
       "2               4869                13         1.523452  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_computing.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "821457ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = pd.read_excel('Output_Data_Structure.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d9de7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_computing['URL'] = output_file['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1975273",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_computing = variable_computing[['URL_ID','URL','POSITIVE SCORE','NEGATIVE SCORE','POLARITY SCORE','SUBJECTIVITY SCORE','AVG SENTENCE LENGTH','PERCENTAGE OF COMPLEX WORDS','FOG INDEX','AVG NUMBER OF WORDS PER SENTENCE','COMPLEX WORD COUNT','WORD COUNT','SYLLABLE PER WORD','PERSONAL PRONOUN','AVG WORD LENGTH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73fe01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_computing.to_excel('output_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac60f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
